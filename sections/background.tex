

\section{Related Works}\label{sec:related}
In this section, we first explore the current development and applications of deep learning in the field of cervical cancer screening, which generally includes detection, segmentation and classification tasks. Then, we present a comprehensive investigation of representation learning and its applications in the field of pathology screening. 

\subsection{Cervical Cancer Screening using Deep Learning}
With the development of deep learning technology, many attempts have been made in automatic cervical cancer screening for resolving the issues of labor-intensive and subjective judgments from the manual screening by pathologists. Generally, all these researches can be divided into two major categories: 1) the detection and segmentation of cervical cells from the WSI, and 2) the classification to aggregate visual features from the cervical cell sets for determining their abnormality. A large number of efforts have been made in the cell-level detection and segmentation tasks, since it is a prerequisite to find suspicious cells from WSIs before further analysis. For example, Zhao et al.\cite{zhao2019automated} developed the Deformable Multipath Ensemble Model (D-MEM) aiming at cervical cell nuclear segmentation, and Zhang et al.\cite{zhang2019binary} further proposed a binary-tree structured cervical cell nuclear segmentation network which incorporates attention mechanisms for improvements of segmentation performance. Zhou et al. ~\cite{zhou2021hierarchical} investigated the current widely-applied detection models including Faster-RCNN\cite{ren2015faster}, YOLO\cite{redmon2018yolov3}, RetinaNet\cite{lin2017focal} and etc., and demonstrated in experiments that RetinaNet has the advantages of both high accuracy and efficiency compared with alternatives in the applications of detecting abnormal cervical cells in WSI. Du et al. \cite{du2021false} proposed a semi-supervised learning method with attention guidance for false positive suppression of cervical cell abnormality detection task.  

On the other hand, the classification task has also played an essential role in the cervical cancer screening pipeline, where it is applied to further refining and determining if the selected cells have abnormality. The corresponding classification methods can be designed either for the cell-level or patch-level which targeting on single cells, or for the image-level or sample-level which focuses more on summarizing the overall screening results from the cervical cell sets under study. Nowadays with the developments of deep learning the classification approaches have become much more advanced with high accuracy and robustness than ever before. Generally, in natural images the classification model is constructed by using the pre-train model as backbone, which can help improve the stability of model training and guarantee the representation capacity of the extracted deep visual features. The most widely-applied pre-train models are VGG and ResNet\cite{bizzego2019evaluating}, and with different configurations such as layer numbers for fitting with various application scenarios. Recently, transformer\cite{vaswani2017attention} technology has drawn attention in the field of deep learning, which is developed based on the self-attention mechanism and has demonstrated its representation ability in the classification tasks. Further extension of transformer has been made in the computer vision domain, and Vision Transformer (ViT) method was proposed by Dosovitskiy et al. \cite{dosovitskiy2020image} which has shown excellent performance on a wide range of visual tasks\cite{xu2022groupvit}, \cite{liu2022cvm}. 
% Add some current developments of classification methods in the computer vision field

Many attempts have also been made in cervical cancer screening using deep learning technology. For example, Zhang et al.\cite{zhang2019binary} developed DeepPap software which implements cell-level classification using convolutional neural network (CNN), and Taha et al.\cite{taha2017classification} proposed the cell-level classification method by firstly using a pre-trained CNN model for feature extraction and then SVM for classification. As for the sample-level classification, Zhou et al. ~\cite{zhou2021hierarchical} proposed a hierarchical framework that progressively gauges the visual features from the detected suspicious cells for the final determination of the WSI screening. However, all the above-mentioned classification methods are implemented by simply ensembling the extracted visual features from the detected cell patches and feeding them into the classification model, without considering the feature status of these patches in the feature space, and therefore cannot conduct comprehensive aggregation of these patch information and undermines the performance of the classification tasks. 

\subsection{Representation Learning and Classification}
With the development of deep learning, the architecture of the constructed model has become increasingly large and complex, and many extracted features from the deep learning models are actually abundant, which undermines its capacity to characterize the target images and achieve classification models with high accuracy. In this way, representation learning has been intensively investigated to solve the above-mentioned issue and further optimize the deep learning model \cite{bengio2013representation}. Generally, representation learning aims at automatically extracting and optimizing the features in a more systematic manner, and can be categorized as supervised, unsupervised and self-supervised learning depending on how we utilize the data labels in the model training. 

Many representation learning methods are developed aiming at finding the optimal features under the given scenarios and machine learning tasks. For example, Weng et al. \cite{weng2019multimodal} used the representation learning method of corresponding feature constraints between different modal images to successfully enable the model to complete multi-task under multi-mode. Moriya et al. \cite{moriya2018unsupervised}used similar clustering methods to aggregate features to achieve better feature representation, so as to provide more precise and accurate features for model segmentation tasks. Besides, there are also many representational learning methods designed for different model characteristics, Liu et al. \cite{liu2021swin} and Rao et al. \cite{rao2021dynamicvit} used the strategy of representation learning in ViT\cite{dosovitskiy2020image}, Adnan et al. \cite{adnan2020representation} used the strategy of representation learning in GCN, which have improved the feature expression efficiency of the models. 
 
Some efforts have also been specifically made in the field of pathology image classification. For example, Boyd et al.\cite{boyd2021self} and Pati et al. \cite{pati2021reducing} used representation learning to add an extra loss on features to help the model do better self-supervised learning with digital pathology. In this paper, we adopt the method of representation learning on the classification models of both patch level and sample level, and independently designed different strategies aiming at improving the feature expression ability of the models, and with experiments to show its effectiveness and robustness.